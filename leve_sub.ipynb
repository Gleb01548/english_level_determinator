{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f38ebda-7a39-4651-89de-542f7cc11340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "from random import shuffle\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import pysrt\n",
    "\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "import optuna\n",
    "\n",
    "#optuna.logging.set_verbosity(optuna.logging.WARNING) \n",
    "\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f754cd3-3022-4dfb-a38e-a358d700bcc6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Анализ таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ec8fcf2-e7f1-4844-a335-659aee64e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('table_pazzle.csv', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "831a7e3d-5104-4fd8-b57b-b778a0cc5cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eadd539-e993-44db-b911-02d513e577a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3561, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e400a10-4695-4e4d-ba3f-870fd9d5ca7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'file_name', 'num_file', 'level'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9918588-7bed-4ba0-b40f-060a1ff519bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>file_name</th>\n",
       "      <th>num_file</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3481</th>\n",
       "      <td>Bliss</td>\n",
       "      <td>Bliss.1997.1080p.WEBRip.x265-RARBG.srt</td>\n",
       "      <td>False</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>Gulliver's Travels</td>\n",
       "      <td>Gulliver's Travels Beyond The Moon (1965).Migh...</td>\n",
       "      <td>False</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>Miss Potter</td>\n",
       "      <td>Miss.Potter.2006.BluRay.H264.AAC-RARBG.en.srt</td>\n",
       "      <td>False</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name                                          file_name  \\\n",
       "3481               Bliss             Bliss.1997.1080p.WEBRip.x265-RARBG.srt   \n",
       "688   Gulliver's Travels  Gulliver's Travels Beyond The Moon (1965).Migh...   \n",
       "2149         Miss Potter      Miss.Potter.2006.BluRay.H264.AAC-RARBG.en.srt   \n",
       "\n",
       "     num_file   level  \n",
       "3481    False    hard  \n",
       "688     False    easy  \n",
       "2149    False  middle  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "742aac48-87f7-486d-9026-90ea764d0b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3504, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82b45629-a8be-492b-989e-64eab2ec0bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df.num_file == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fddda771-e376-459b-bcb4-27f443108606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "middle    1831\n",
       "easy      1105\n",
       "hard       568\n",
       "Name: level, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f81e4fa2-5e21-420a-91c2-eac16aac5636",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_file = []\n",
    "for name in df['file_name']:\n",
    "    try:\n",
    "        pysrt.open(f'sub/{name}', encoding='iso-8859-1')\n",
    "    except:\n",
    "        error_file.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36e03f14-a17b-4dd4-bf6a-12b5651fef13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(error_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e281b333-9b26-42f1-a444-7d365162be5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3461, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.file_name.isin(error_file) == False]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b719ab9-fca2-403b-a7b0-eeb4bbcfa08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "middle    1812\n",
       "easy      1088\n",
       "hard       561\n",
       "Name: level, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fc84708-44df-4e94-89b8-ba7909087da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "middle    0.523548\n",
       "easy      0.314360\n",
       "hard      0.162092\n",
       "Name: level, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['level'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cca0f0f9-20b0-4092-a7af-4c17f750fc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('final_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c31b12-2a45-4a13-9e00-a4c43545568e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Токенезируем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "631ab7e8-583c-4032-810e-c9a03279eed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_table.csv', dtype=str, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "513c6694-ac85-4d91-9e0f-c537d80a944b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test(df):\n",
    "    index_test = []\n",
    "    for level_name in df['level'].unique():\n",
    "        len_level = df[df['level'] == level_name].shape[0]\n",
    "        index_test.extend(list((df['level'] == level_name).sample(int(len_level*20/100)).index))\n",
    "    df_train = df.drop(index_test).copy()\n",
    "    df_test = df.loc[index_test].copy()\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffd19e87-dde9-4259-85da-f87d169df807",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = make_test(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cda4d305-6fb4-42fa-9a07-d296cfbe3a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(middle    1454\n",
       " easy       903\n",
       " hard       457\n",
       " Name: level, dtype: int64,\n",
       " middle    377\n",
       " easy      200\n",
       " hard      114\n",
       " Name: level, dtype: int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['level'].value_counts(), df_test['level'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "68c47b65-c1cc-4fe4-8b28-62f1fd5df60f",
   "metadata": {},
   "source": [
    "# без стоп-слов\n",
    "def tokens_df(srt, tokenizer, stop_words):\n",
    "    tokens_list = []\n",
    "    srt = [string.text for string in srt]\n",
    "    for string in tokenizer.tokenizer.pipe(srt, batch_size=2000):\n",
    "        tokens = tokenizer(string)\n",
    "        tokens_list.extend([str(token).lower() for token in tokens \\\n",
    "                            if token.is_alpha and str(token).lower() not in stop_words])\n",
    "    return tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d99aeef-435b-48f3-ad3c-898587bba66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# со стоп-словами\n",
    "def tokens_df(srt, tokenizer, stop_words):\n",
    "    tokens_list = []\n",
    "    srt = [string.text for string in srt]\n",
    "    for string in tokenizer.tokenizer.pipe(srt, batch_size=2000):\n",
    "        tokens = tokenizer(string)\n",
    "        tokens_list.extend([str(token).lower() for token in tokens \\\n",
    "                            if token.is_alpha])\n",
    "    return tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c121d6db-e3ad-4372-b37e-4037417a3643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "nlp = English()\n",
    "num = 0\n",
    "pbar = tqdm(df_train['file_name'], leave=False)\n",
    "level = {'easy':0, 'middle':1, 'hard':2}\n",
    "\n",
    "train_list = []\n",
    "counter_words = Counter()\n",
    "counter_label = Counter()\n",
    "len_list = []\n",
    "\n",
    "for index, name in enumerate(pbar):\n",
    "    num+= 1\n",
    "    label = level[df_train.iloc[index]['level']]\n",
    "    name_film = df_train.iloc[index]['name']\n",
    "    \n",
    "    srt = pysrt.open(f'sub/{name}', encoding='iso-8859-1')\n",
    "    tokens = tokens_df(srt, nlp, stop_words)\n",
    "    \n",
    "    len_list.append(len(tokens))\n",
    "    counter_words.update(tokens)\n",
    "    counter_label.update(str(label))\n",
    "    \n",
    "    train_list.append((tokens, label, name_film))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d59806d5-16d6-439b-b275-475ff15883eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122212"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counter_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31af8cbf-7023-4b68-8211-3c7b16e45701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1631edd-ea4a-44c3-a02d-0c7289b351bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/691 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pbar = tqdm(df_test['file_name'], leave=False)\n",
    "\n",
    "test_list = []\n",
    "\n",
    "for index, name in enumerate(pbar):\n",
    "    label = level[df_test.iloc[index]['level']]\n",
    "    name_film = df_test.iloc[index]['name']\n",
    "    \n",
    "    srt = pysrt.open(f'sub/{name}', encoding='iso-8859-1')\n",
    "    tokens = tokens_df(srt, nlp, stop_words)\n",
    "    test_list.append((tokens, label, name_film))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d5af9af-47da-46e8-884f-2202c4759c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'train_list' (list)\n",
      "Stored 'test_list' (list)\n",
      "Stored 'counter_words' (Counter)\n",
      "Stored 'counter_label' (Counter)\n",
      "Stored 'len_list' (list)\n"
     ]
    }
   ],
   "source": [
    "%store train_list\n",
    "%store test_list\n",
    "%store counter_words\n",
    "%store counter_label\n",
    "%store len_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f273a34f-e5d4-46a1-a7c4-a669bef1c1a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(len_list).hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90dfa0eb-415f-4e22-b910-92ef0e0f06c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24748"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(len_list).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97df1049-a1b8-4c13-9782-20569a1acc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7972.0\n",
      "8759.0\n",
      "10157.0\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(len_list).quantile(0.5))\n",
    "print(pd.Series(len_list).quantile(0.6))\n",
    "print(pd.Series(len_list).quantile(0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dedcb015-ce2a-4067-9838-f91bb93046ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_words = [i[0] for i in train_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539c77ce-4cba-4c01-a93e-a45054bb9eb7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Обучаем на эмбединге"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36685d8-8f4b-4ae9-a5b2-fff828a38215",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Загружаем word2vec модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cfe41e0-ef2a-42d7-9152-497371072e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5a923df-cf37-4484-a77d-99777f866ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = KeyedVectors.load(\"models/word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84007345-8400-4f07-a2bc-80ff03ce839a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Формируем батчи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39637e70-dc71-45e7-a464-c4b6a366dda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_string(list_result, index_dict, LEN_STRI):\n",
    "    data = []\n",
    "    for tokens, label, name in list_result:\n",
    "        # прибавляем 2, так как при создании эмбеддингов это 0 pad, 1 unknow\n",
    "        stri = list(map(lambda x: index_dict.get(x, -1)+2, tokens[:LEN_STRI]))\n",
    "        stri = stri + [0]*(LEN_STRI - len(stri)) if len(stri) < LEN_STRI else stri\n",
    "        data.append((torch.LongTensor(stri), label, name)\n",
    "                   )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ea9b666-d9d9-4b03-a197-3d9b7fb6080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEN_STRI = 2000\n",
    "train_data = trans_string(train_list, wv.key_to_index, LEN_STRI)\n",
    "test_data = trans_string(test_list, wv.key_to_index, LEN_STRI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a503f34d-f7bd-4cd3-906d-eb8d935de2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c573429b-dceb-4032-9946-53d12ebe6036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2000])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "train_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "463f5a16-6a60-4b31-9280-99c6185a4def",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, \n",
    "                                           shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(test_data, batch_size=64, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea3524a-4461-4153-a207-1a5803c11579",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Создаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e19abc2-d56e-4315-942d-6a6bac827303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_string(list_result, index_dict, LEN_STRI):\n",
    "    data = []\n",
    "    for tokens, label, name in list_result:\n",
    "        # прибавляем 2, так как при создании эмбеддингов это 0 pad, 1 unknow\n",
    "        stri = list(map(lambda x: index_dict.get(x, -1)+2, tokens[:LEN_STRI]))\n",
    "        stri = stri + [0]*(LEN_STRI - len(stri)) if len(stri) < LEN_STRI else stri\n",
    "        data.append((torch.LongTensor(stri), label, name)\n",
    "                   )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e86fff-9c6f-460f-9d61-ffe2ca3539b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEN_STRI = 2000\n",
    "train_data = trans_string(train_list, wv.key_to_index, LEN_STRI)\n",
    "test_data = trans_string(test_list, wv.key_to_index, LEN_STRI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd778fa-d07e-4845-9956-8492a97e41df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, \n",
    "                                           shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(test_data, batch_size=64, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3ceaec4-72af-41b4-b99e-292fde270c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNBaseline(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "                \n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, \n",
    "                           n_layers, bidirectional=bidirectional,\n",
    "                           dropout=dropout)\n",
    "        \n",
    "        hidden_dim = hidden_dim*n_layers if bidirectional == False else hidden_dim*n_layers*2\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.Flatten(), \n",
    "                                nn.Linear(hidden_dim, int(hidden_dim/2)),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(int(hidden_dim/2), output_dim)\n",
    "                               )\n",
    "        \n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        embedded = embedded.permute(1, 0, 2)\n",
    "        \n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "\n",
    "        hidden = hidden.permute(1, 0, 2)\n",
    "        fc = self.fc(hidden)\n",
    "            \n",
    "        return fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd6322e9-be0a-4204-9393-774dcb7cab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = wv['cat'].shape[0]\n",
    "output_dim = len(counter_label)\n",
    "n_layers = 1\n",
    "bidirectional = True\n",
    "dropout = 0\n",
    "pad_idx = 0\n",
    "model = RNNBaseline(len(wv.key_to_index)+2, embed_dim, \n",
    "                    embed_dim, output_dim, n_layers, \n",
    "                   bidirectional, dropout, pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e20ed49-a3cd-4019-9649-233a6e4b8912",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27916/115841204.py:4: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525539683/work/torch/csrc/utils/tensor_numpy.cpp:199.)\n",
      "  model.embedding.weight[idx+2] = torch.Tensor(wv.get_vector(word))\n"
     ]
    }
   ],
   "source": [
    "# меняем веса у эмбединга как у word2vec \n",
    "with torch.no_grad():\n",
    "    for word, idx in wv.key_to_index.items():\n",
    "        model.embedding.weight[idx+2] = torch.Tensor(wv.get_vector(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4f4a709-beae-45f8-ac2e-87d1b29d23fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_embeddings(model, req_grad=False):\n",
    "    embeddings = model.embedding\n",
    "    for c_p in embeddings.parameters():\n",
    "        c_p.requires_grad = req_grad\n",
    "freeze_embeddings(model, req_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2bd5e17-c8fe-47f8-8f04-181b73be8429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNBaseline(\n",
       "  (embedding): Embedding(3000002, 300, padding_idx=0)\n",
       "  (rnn): LSTM(300, 300, bidirectional=True)\n",
       "  (fc): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=600, out_features=300, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=300, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6919cc4e-ffd3-4e1d-abd3-f55ac0cb1f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, loss, optimizer, num_epochs):    \n",
    "    loss_history = []\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Enter train mode\n",
    "        \n",
    "        loss_accum = 0\n",
    "        correct_samples = 0\n",
    "        total_samples = 0\n",
    "        for i_step, data in enumerate(train_loader):\n",
    "            # print(data[0].shape)\n",
    "            # print(data[1].shape)\n",
    "            # input()\n",
    "            \n",
    "            x_gpu = data[0].to(device)\n",
    "            y_gpu = data[1].to(device)\n",
    "            prediction = model(x_gpu)  \n",
    "            \n",
    "            loss_value = loss(prediction, y_gpu)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, indices = torch.max(prediction, 1)\n",
    "            correct_samples += torch.sum(indices == y_gpu)\n",
    "            total_samples += y_gpu.shape[0]\n",
    "            \n",
    "            loss_accum += loss_value\n",
    "        \n",
    "        ave_loss = loss_accum / i_step\n",
    "        train_accuracy = float(correct_samples) / total_samples\n",
    "        val_accuracy = compute_accuracy(model, val_loader)\n",
    "        \n",
    "        loss_history.append(float(ave_loss))\n",
    "        train_history.append(train_accuracy)\n",
    "        val_history.append(val_accuracy)\n",
    "        \n",
    "        print(f'Average loss:{ave_loss}, train_accuracy: {round(train_accuracy, 2)},\\\n",
    "              val_accuracy: {round(val_accuracy, 2)}')\n",
    "        \n",
    "    return loss_history, train_history, val_history\n",
    "        \n",
    "def compute_accuracy(model, loader):\n",
    "\n",
    "    predict_list = []\n",
    "    y_list = []\n",
    "    model.eval() # Evaluation mode\n",
    "    for data in loader:\n",
    "        X = data[0].to(device)\n",
    "        y = data[1].to(device)\n",
    "        prediction = model(X)\n",
    "        _, index = torch.max(prediction, 1)\n",
    "        predict_list.extend(list(index.cpu()))\n",
    "        y_list.extend(list(y.cpu()))\n",
    "        \n",
    "    accuracy = float(sum([pred == gt for pred, gt in zip(predict_list, y_list)])) / len(predict_list)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f51f1441-46ba-461b-a916-f3e25bfc7960",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [{'params': model.rnn.parameters()},\n",
    "              {'params': model.fc.parameters()}\n",
    "              ]\n",
    "\n",
    "opt = torch.optim.Adam(parameters)\n",
    "loss_func = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
    "max_epochs = 20"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee65180d-74c0-44f6-8c0f-b5d63db07eca",
   "metadata": {},
   "source": [
    "!export 'PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:256'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aaa652fc-0734-4592-9318-f99da8e8cff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss:1.0357723236083984, train_accuracy: 0.52,              val_accuracy: 0.52\n",
      "Average loss:0.9997428059577942, train_accuracy: 0.53,              val_accuracy: 0.51\n",
      "Average loss:0.9713132977485657, train_accuracy: 0.55,              val_accuracy: 0.46\n",
      "Average loss:0.9087525010108948, train_accuracy: 0.59,              val_accuracy: 0.49\n",
      "Average loss:0.8320738077163696, train_accuracy: 0.64,              val_accuracy: 0.49\n",
      "Average loss:0.6983506083488464, train_accuracy: 0.72,              val_accuracy: 0.48\n",
      "Average loss:0.5580732226371765, train_accuracy: 0.79,              val_accuracy: 0.44\n",
      "Average loss:0.41863834857940674, train_accuracy: 0.85,              val_accuracy: 0.44\n",
      "Average loss:0.29247087240219116, train_accuracy: 0.9,              val_accuracy: 0.46\n",
      "Average loss:0.2100418508052826, train_accuracy: 0.93,              val_accuracy: 0.45\n",
      "Average loss:0.14015516638755798, train_accuracy: 0.95,              val_accuracy: 0.44\n",
      "Average loss:0.1218351349234581, train_accuracy: 0.96,              val_accuracy: 0.44\n",
      "Average loss:0.08283901959657669, train_accuracy: 0.97,              val_accuracy: 0.46\n",
      "Average loss:0.06881789118051529, train_accuracy: 0.98,              val_accuracy: 0.46\n",
      "Average loss:0.054925043135881424, train_accuracy: 0.98,              val_accuracy: 0.45\n",
      "Average loss:0.053231049329042435, train_accuracy: 0.98,              val_accuracy: 0.44\n",
      "Average loss:0.0452411025762558, train_accuracy: 0.98,              val_accuracy: 0.45\n",
      "Average loss:0.039878956973552704, train_accuracy: 0.98,              val_accuracy: 0.43\n",
      "Average loss:0.030873456969857216, train_accuracy: 0.98,              val_accuracy: 0.44\n",
      "Average loss:0.02877792902290821, train_accuracy: 0.98,              val_accuracy: 0.45\n"
     ]
    }
   ],
   "source": [
    "loss_history, train_history, val_history \\\n",
    "= train_model(model, train_loader, val_loader, loss_func, opt, max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ffda7fac-4097-4c07-b882-5c819cee5668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  7528,  18521, 931438,  ...,  26669,   3321,    239])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d0054a9-25ac-4dd6-bcb4-1f9a3593e996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ebbf57b-30d3-4b30-a6f6-b19cffcbb574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 300])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding(test_data[0][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "415563fd-f622-40a2-b8b0-fd92fdf238e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "qw = model.embedding(test_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cda3bb26-b494-4fa9-9fed-cf0d10a31504",
   "metadata": {},
   "outputs": [],
   "source": [
    "qw = test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5aa5690c-42d3-4200-9e50-e3f43b9a0f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "qw = qw[None, None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "99fa5879-fcb4-4db9-967f-e2e1a5279361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2000])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b00c5ab-e938-4220-a60b-24c95d4450b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 4 is not equal to len(dims) = 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27916/3601938145.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_27916/2294004657.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 4 is not equal to len(dims) = 3"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.to('cpu')\n",
    "model(qw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa73199-2b54-4296-b686-18d1f1cecabe",
   "metadata": {},
   "source": [
    "# Формируем эмбединги с нуля "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "abd51977-280e-4a50-a208-dbe2ba32e616",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word = {word:ind+2 for ind, word in enumerate(counter_words.keys())}\n",
    "index_word['<PAD>'] = 0\n",
    "index_word['<unknow>'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ff9a9f1-d2f0-4315-a78b-b35bb74fc950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_string(list_result, index_dict, LEN_STRI):\n",
    "    data = []\n",
    "    for tokens, label, name in list_result:\n",
    "        # прибавляем 2, так как при создании эмбеддингов это 0 pad, 1 unknow\n",
    "        stri = list(map(lambda x: index_dict.get(x, 1), tokens[:LEN_STRI]))\n",
    "        stri = stri + [0]*(LEN_STRI - len(stri)) if len(stri) < LEN_STRI else stri\n",
    "        data.append((torch.LongTensor(stri), label, name)\n",
    "                   )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e3a56b52-6cb1-49bb-8df7-d59ac49ca50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEN_STRI = 150\n",
    "train_data = trans_string(train_list, index_word, LEN_STRI)\n",
    "test_data = trans_string(test_list, index_word, LEN_STRI)\n",
    "shuffle(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e014b0bd-8557-44b7-b78d-3247aec92ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, \n",
    "                                           shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(test_data, batch_size=64, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e5b2408-00a8-4bf5-bc8c-2a693dcc5a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNBaseline(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "                \n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, \n",
    "                           n_layers, bidirectional=bidirectional,\n",
    "                           dropout=dropout)\n",
    "        \n",
    "        hidden_dim = hidden_dim*n_layers if bidirectional == False else hidden_dim*n_layers*2\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.Flatten(), \n",
    "                                nn.Linear(hidden_dim, int(hidden_dim/2)),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(int(hidden_dim/2), output_dim)\n",
    "                               )\n",
    "        \n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        embedded = embedded.permute(1, 0, 2)\n",
    "        \n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "\n",
    "        hidden = hidden.permute(1, 0, 2)\n",
    "        fc = self.fc(hidden)\n",
    "            \n",
    "        return fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cc3cc5ac-a005-43c9-bb2b-be61dadd35cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 100\n",
    "output_dim = len(counter_label)\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "bidirectional = True\n",
    "dropout = 0\n",
    "pad_idx = 0\n",
    "model = RNNBaseline(len(index_word), embed_dim, \n",
    "                    embed_dim, output_dim, n_layers, \n",
    "                   bidirectional, dropout, pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "28c2d38c-67b1-42ed-8ae1-9e2989ee359d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNBaseline(\n",
       "  (embedding): Embedding(122214, 100, padding_idx=0)\n",
       "  (rnn): LSTM(100, 100, num_layers=2, bidirectional=True)\n",
       "  (fc): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=400, out_features=200, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=200, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c6088ab4-9c86-4d72-bb98-540028fc7a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters())\n",
    "loss_func = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
    "max_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aa65ea4-beae-44c4-a207-46a40890e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, loss, optimizer, num_epochs):    \n",
    "    loss_history = []\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Enter train mode\n",
    "        \n",
    "        loss_accum = 0\n",
    "        correct_samples = 0\n",
    "        total_samples = 0\n",
    "        for i_step, data in enumerate(train_loader):\n",
    "            # print(data[0].shape)\n",
    "            # print(data[1].shape)\n",
    "            # input()\n",
    "            \n",
    "            x_gpu = data[0].to(device)\n",
    "            y_gpu = data[1].to(device)\n",
    "            prediction = model(x_gpu)  \n",
    "            \n",
    "            loss_value = loss(prediction, y_gpu)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, indices = torch.max(prediction, 1)\n",
    "            correct_samples += torch.sum(indices == y_gpu)\n",
    "            total_samples += y_gpu.shape[0]\n",
    "            \n",
    "            loss_accum += loss_value\n",
    "        \n",
    "        ave_loss = loss_accum / i_step\n",
    "        train_accuracy = float(correct_samples) / total_samples\n",
    "        val_accuracy = compute_accuracy(model, val_loader)\n",
    "        \n",
    "        loss_history.append(float(ave_loss))\n",
    "        train_history.append(train_accuracy)\n",
    "        val_history.append(val_accuracy)\n",
    "        \n",
    "        print(f'Average loss:{ave_loss}, train_accuracy: {round(train_accuracy, 2)},\\\n",
    "              val_accuracy: {round(val_accuracy, 2)}')\n",
    "        \n",
    "    return loss_history, train_history, val_history\n",
    "        \n",
    "def compute_accuracy(model, loader):\n",
    "\n",
    "    predict_list = []\n",
    "    y_list = []\n",
    "    model.eval() # Evaluation mode\n",
    "    for data in loader:\n",
    "        X = data[0].to(device)\n",
    "        y = data[1].to(device)\n",
    "        prediction = model(X)\n",
    "        _, index = torch.max(prediction, 1)\n",
    "        predict_list.extend(list(index.cpu()))\n",
    "        y_list.extend(list(y.cpu()))\n",
    "        \n",
    "    accuracy = float(sum([pred == gt for pred, gt in zip(predict_list, y_list)])) / len(predict_list)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bb1c3602-55f6-4787-aa6a-84b389145cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss:1.0374284982681274, train_accuracy: 0.52,              val_accuracy: 0.55\n",
      "Average loss:0.9894651174545288, train_accuracy: 0.53,              val_accuracy: 0.55\n",
      "Average loss:0.8946910500526428, train_accuracy: 0.58,              val_accuracy: 0.42\n",
      "Average loss:0.697466254234314, train_accuracy: 0.71,              val_accuracy: 0.43\n",
      "Average loss:0.4155140817165375, train_accuracy: 0.84,              val_accuracy: 0.45\n",
      "Average loss:0.22731009125709534, train_accuracy: 0.93,              val_accuracy: 0.42\n",
      "Average loss:0.12437214702367783, train_accuracy: 0.97,              val_accuracy: 0.43\n",
      "Average loss:0.0937967374920845, train_accuracy: 0.98,              val_accuracy: 0.44\n",
      "Average loss:0.07488717883825302, train_accuracy: 0.98,              val_accuracy: 0.42\n",
      "Average loss:0.05567287653684616, train_accuracy: 0.98,              val_accuracy: 0.47\n",
      "Average loss:0.04208597168326378, train_accuracy: 0.98,              val_accuracy: 0.44\n",
      "Average loss:0.037755709141492844, train_accuracy: 0.98,              val_accuracy: 0.46\n",
      "Average loss:0.035500336438417435, train_accuracy: 0.98,              val_accuracy: 0.44\n",
      "Average loss:0.028340667486190796, train_accuracy: 0.98,              val_accuracy: 0.44\n",
      "Average loss:0.02758660726249218, train_accuracy: 0.98,              val_accuracy: 0.43\n",
      "Average loss:0.02545943111181259, train_accuracy: 0.98,              val_accuracy: 0.43\n",
      "Average loss:0.025037681683897972, train_accuracy: 0.98,              val_accuracy: 0.45\n",
      "Average loss:0.023388879373669624, train_accuracy: 0.98,              val_accuracy: 0.46\n",
      "Average loss:0.022434594109654427, train_accuracy: 0.98,              val_accuracy: 0.45\n",
      "Average loss:0.022584298625588417, train_accuracy: 0.98,              val_accuracy: 0.43\n"
     ]
    }
   ],
   "source": [
    "loss_history, train_history, val_history \\\n",
    "= train_model(model, train_loader, val_loader, loss_func, opt, max_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dad0e9-d1b4-4ba2-a6ce-fda10a7a34ef",
   "metadata": {},
   "source": [
    "# Пробуем увеличить количество данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7de0d6ce-9f2a-46d4-88e7-957db5c0abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word = {word:ind+2 for ind, word in enumerate(counter_words.keys())}\n",
    "index_word['<PAD>'] = 0\n",
    "index_word['<unknow>'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5bcdad2e-f5bf-4499-a2ec-cbf6e4dd2029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_string(list_result, index_dict, LEN_STRI):\n",
    "    data = []\n",
    "    for tokens, label, name in list_result:\n",
    "        for index_start, index_end in zip(range(0, len(tokens), LEN_STRI), \n",
    "                                          range(LEN_STRI, len(tokens)+LEN_STRI, LEN_STRI)):\n",
    "        \n",
    "            stri = list(map(lambda x: index_dict.get(x, 1), tokens[index_start:index_end]))\n",
    "            stri = stri + [0]*(LEN_STRI - len(stri)) if len(stri) < LEN_STRI else stri\n",
    "            data.append((torch.LongTensor(stri), label, name)\n",
    "                       )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8cba4398-d8dd-483a-b1ea-cc9efd430d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEN_STRI = 100\n",
    "train_data_many = trans_string(train_list, index_word, LEN_STRI)\n",
    "test_data_many = trans_string(test_list, index_word, LEN_STRI)\n",
    "shuffle(train_data_many)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "44c1f371-c3ce-4d91-99a1-5d84f5668b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'train_data_many' (list)\n",
      "Stored 'test_data_many' (list)\n"
     ]
    }
   ],
   "source": [
    "%store train_data_many\n",
    "%store test_data_many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5b4758b6-b12b-4d91-a554-8f29744d7b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138633"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e54e64d7-0328-4cb1-9550-24898e714d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_many[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fed60968-679f-4009-9267-1185bb368d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = 0 \n",
    "one = 0\n",
    "two = 0\n",
    "qw = set()\n",
    "for i in range(len(train_data_many)):\n",
    "    qw.add(len(train_data_many[i][0]))\n",
    "    if train_data_many[i][1] == 0:\n",
    "        zero += 1\n",
    "    elif train_data_many[i][1] == 1:\n",
    "        one += 1\n",
    "    elif train_data_many[i][1] == 2:\n",
    "        two += 1\n",
    "    else: \n",
    "        print('ошибка')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "491f86b1-df1b-4408-9a00-a61c71b47449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{100}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a07c16d7-1236-4efb-a542-c65cd5acb392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70709, 122142, 37962)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero, one, two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c27bc7ed-c20e-4014-8728-b64f735f2b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data_many, batch_size=64, \n",
    "                                           shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(test_data_many, batch_size=64, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53a3ba87-8f34-49a9-8329-4104e7d383f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNBaseline(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "                \n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, \n",
    "                           n_layers, bidirectional=bidirectional,\n",
    "                           dropout=dropout)\n",
    "        \n",
    "        hidden_dim = hidden_dim*n_layers if bidirectional == False else hidden_dim*n_layers*2\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.Flatten(), \n",
    "                                nn.Linear(hidden_dim, int(hidden_dim/2)),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(int(hidden_dim/2), output_dim)\n",
    "                               )\n",
    "        \n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        embedded = embedded.permute(1, 0, 2)\n",
    "        \n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "\n",
    "        hidden = hidden.permute(1, 0, 2)\n",
    "        fc = self.fc(hidden)\n",
    "            \n",
    "        return fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cd52899a-d106-4a3b-96da-bf7e5ac9ef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 50\n",
    "output_dim = len(counter_label)\n",
    "hidden_dim = 100\n",
    "n_layers = 2\n",
    "bidirectional = True\n",
    "dropout = 0.3\n",
    "pad_idx = 0\n",
    "model = RNNBaseline(len(index_word), embed_dim, \n",
    "                    hidden_dim, output_dim, n_layers, \n",
    "                   bidirectional, dropout, pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b94bc492-f088-4c9a-ad45-639a8a693513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNBaseline(\n",
       "  (embedding): Embedding(122214, 50, padding_idx=0)\n",
       "  (rnn): LSTM(50, 100, num_layers=2, dropout=0.3, bidirectional=True)\n",
       "  (fc): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=400, out_features=200, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=200, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5e9f30b3-82ca-4c77-a1c1-7387c16d83f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_func = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
    "max_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad8614f-2e26-4716-8742-f1e8a459970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, loss, optimizer, num_epochs):    \n",
    "    loss_history = []\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Enter train mode\n",
    "        \n",
    "        loss_accum = 0\n",
    "        correct_samples = 0\n",
    "        total_samples = 0\n",
    "        for i_step, data in enumerate(train_loader):\n",
    "            # print(data[0].shape)\n",
    "            # print(data[1].shape)\n",
    "            # input()\n",
    "            \n",
    "            x_gpu = data[0].to(device)\n",
    "            y_gpu = data[1].to(device)\n",
    "            prediction = model(x_gpu)  \n",
    "            \n",
    "            loss_value = loss(prediction, y_gpu)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, indices = torch.max(prediction, 1)\n",
    "            correct_samples += torch.sum(indices == y_gpu)\n",
    "            total_samples += y_gpu.shape[0]\n",
    "            \n",
    "            loss_accum += loss_value\n",
    "        \n",
    "        ave_loss = loss_accum / i_step\n",
    "        train_accuracy = float(correct_samples) / total_samples\n",
    "        val_accuracy = compute_accuracy(model, val_loader)\n",
    "        \n",
    "        loss_history.append(float(ave_loss))\n",
    "        train_history.append(train_accuracy)\n",
    "        val_history.append(val_accuracy)\n",
    "        \n",
    "        print(f'{epoch}. Average loss:{ave_loss}, train_accuracy: {round(train_accuracy, 2)},\\\n",
    "              val_accuracy: {round(val_accuracy, 2)}')\n",
    "        \n",
    "    return loss_history, train_history, val_history\n",
    "        \n",
    "def compute_accuracy(model, loader):\n",
    "\n",
    "    predict_list = []\n",
    "    y_list = []\n",
    "    model.eval() # Evaluation mode\n",
    "    for data in loader:\n",
    "        X = data[0].to(device)\n",
    "        y = data[1].to(device)\n",
    "        prediction = model(X)\n",
    "        _, index = torch.max(prediction, 1)\n",
    "        predict_list.extend(list(index.cpu()))\n",
    "        y_list.extend(list(y.cpu()))\n",
    "        \n",
    "    accuracy = float(sum([pred == gt for pred, gt in zip(predict_list, y_list)])) / len(predict_list)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7eb46e5c-9957-453e-ad45-6d2041ad34cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Average loss:0.9968255758285522, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "1. Average loss:0.9865835905075073, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "2. Average loss:0.9715284705162048, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "3. Average loss:0.9535956382751465, train_accuracy: 0.55,              val_accuracy: 0.55\n",
      "4. Average loss:0.9370211362838745, train_accuracy: 0.56,              val_accuracy: 0.56\n",
      "5. Average loss:0.9214831590652466, train_accuracy: 0.57,              val_accuracy: 0.56\n",
      "6. Average loss:0.9063810110092163, train_accuracy: 0.58,              val_accuracy: 0.54\n",
      "7. Average loss:0.8903160095214844, train_accuracy: 0.59,              val_accuracy: 0.56\n",
      "8. Average loss:0.874950110912323, train_accuracy: 0.6,              val_accuracy: 0.55\n",
      "9. Average loss:0.8598862886428833, train_accuracy: 0.61,              val_accuracy: 0.55\n",
      "10. Average loss:0.8444107174873352, train_accuracy: 0.62,              val_accuracy: 0.55\n",
      "11. Average loss:0.8290818929672241, train_accuracy: 0.63,              val_accuracy: 0.54\n",
      "12. Average loss:0.8134743571281433, train_accuracy: 0.64,              val_accuracy: 0.53\n",
      "13. Average loss:0.7984012365341187, train_accuracy: 0.65,              val_accuracy: 0.52\n",
      "14. Average loss:0.7828993201255798, train_accuracy: 0.66,              val_accuracy: 0.54\n",
      "15. Average loss:0.7677887678146362, train_accuracy: 0.66,              val_accuracy: 0.52\n",
      "16. Average loss:0.7526134848594666, train_accuracy: 0.67,              val_accuracy: 0.53\n",
      "17. Average loss:0.7372862100601196, train_accuracy: 0.68,              val_accuracy: 0.5\n",
      "18. Average loss:0.7220577001571655, train_accuracy: 0.69,              val_accuracy: 0.53\n",
      "19. Average loss:0.707655668258667, train_accuracy: 0.7,              val_accuracy: 0.52\n"
     ]
    }
   ],
   "source": [
    "loss_history, train_history, val_history \\\n",
    "= train_model(model, train_loader, val_loader, loss_func, opt, max_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8095c689-257b-47c5-b5ca-d2283d95f259",
   "metadata": {},
   "source": [
    "Удалось уменьшить скорость переобучения, но не остановаить его. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb5e4d6-b029-45af-8b88-bd0100ea8d5e",
   "metadata": {},
   "source": [
    "# Попробуем использовать optuna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "120689a8-6016-4f3c-940b-e24606222b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a2c14e6-9289-44ca-82f4-c9ae867cdce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word = {word:ind+2 for ind, word in enumerate(counter_words.keys())}\n",
    "index_word['<PAD>'] = 0\n",
    "index_word['<unknow>'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7114f8d6-5161-439e-ab15-28ba7026f778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_string(list_result, index_dict, LEN_STRI):\n",
    "    data = []\n",
    "    for tokens, label, name in list_result:\n",
    "        for index_start, index_end in zip(range(0, len(tokens), LEN_STRI), \n",
    "                                          range(LEN_STRI, len(tokens)+LEN_STRI, LEN_STRI)):\n",
    "        \n",
    "            stri = list(map(lambda x: index_dict.get(x, 1), tokens[index_start:index_end]))\n",
    "            stri = stri + [0]*(LEN_STRI - len(stri)) if len(stri) < LEN_STRI else stri\n",
    "            data.append((torch.LongTensor(stri), label, name)\n",
    "                       )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dfcf826-d762-41c1-9f2e-78f4c88f94eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(train_list, test_list, index_word, LEN_STRI):\n",
    "    #LEN_STRI = 100\n",
    "    train_data_many = trans_string(train_list, index_word, LEN_STRI)\n",
    "    test_data_many = trans_string(test_list, index_word, LEN_STRI)\n",
    "    shuffle(train_data_many)\n",
    "    train_loader = torch.utils.data.DataLoader(train_data_many, batch_size=64, \n",
    "                                               shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(test_data_many, batch_size=64, \n",
    "                                               shuffle=True)    \n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ede6611d-9059-41dc-bdee-66fcedadd403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(vocab_size, embed_dim, hidden_dim, output_dim,\n",
    "               n_layers, bidirectional, dropout):\n",
    "    # vocab_size = len(index_word)\n",
    "    # embed_dim = 50\n",
    "    # output_dim = len(counter_label)\n",
    "    # hidden_dim = 100\n",
    "    # n_layers = 2\n",
    "    # bidirectional = True\n",
    "    # dropout = 0.3\n",
    "    # pad_idx = 0\n",
    "    model = RNNBaseline(vocab_size, embed_dim, \n",
    "                        embed_dim, output_dim, n_layers, \n",
    "                       bidirectional, dropout, pad_idx=0)\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "559d05c9-45a4-45e1-92bf-1b1cdbbd0128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluet(param):\n",
    "    global train_list, test_list, index_word, counter_label\n",
    "    \n",
    "    train_loader, val_loader = make_batch(train_list, test_list, \n",
    "                                          index_word, param['LEN_STRI'])\n",
    "    model = make_model(len(index_word), param['embed_dim'], param['hidden_dim'], \n",
    "                       len(counter_label), param['n_layers'], True, \n",
    "                       param['dropout'])\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=param['lr'])\n",
    "    loss_func = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
    "    loss_history, train_history, val_history \\\n",
    "    = train_model(model, train_loader, val_loader, loss_func, opt, param['epochs'])   \n",
    "    \n",
    "    return val_history[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbdc8f1c-42ea-4e3e-a7a9-4acb144164c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    global history \n",
    "     \n",
    "    params = {\n",
    "          'lr': trial.suggest_float('learning_rate', 1.5e-5, 1.5e-5),\n",
    "          'epochs': trial.suggest_int(\"epochs\", 25, 50),\n",
    "          'LEN_STRI': trial.suggest_int(\"LEN_STRI\", 50, 250), \n",
    "          'embed_dim': trial.suggest_int(\"embed_dim\", 10, 250), \n",
    "          'hidden_dim': trial.suggest_int(\"hidden_dim\", 10, 250),\n",
    "          'n_layers': trial.suggest_int(\"n_layers\", 1, 3),\n",
    "          'dropout': trial.suggest_float(\"dropout\", 0, 0.4),\n",
    "          }\n",
    "\n",
    "    accuracy = train_and_evaluet(params)\n",
    "    history.append((params, accuracy))\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2e1bac-21ca-46cf-b765-975d7119645e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-15 00:07:17,682]\u001b[0m A new study created in memory with name: no-name-d20467af-a532-4468-85cc-258cf4776b79\u001b[0m\n",
      "/home/gleb/anaconda3/lib/python3.9/site-packages/optuna/progress_bar.py:56: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd182d7883bf42ea8fcb7ce55236415c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gleb/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.21036589764735192 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Average loss:1.0190098285675049, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "1. Average loss:0.997289776802063, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "2. Average loss:0.9956587553024292, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "3. Average loss:0.994360089302063, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "4. Average loss:0.9931449890136719, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "5. Average loss:0.9919558167457581, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "6. Average loss:0.9906361699104309, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "7. Average loss:0.9892062544822693, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "8. Average loss:0.9876035451889038, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "9. Average loss:0.9858771562576294, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "10. Average loss:0.9838737845420837, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "11. Average loss:0.981521725654602, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "12. Average loss:0.9783803820610046, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "13. Average loss:0.9733872413635254, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "14. Average loss:0.965592622756958, train_accuracy: 0.53,              val_accuracy: 0.55\n",
      "15. Average loss:0.958868145942688, train_accuracy: 0.54,              val_accuracy: 0.55\n",
      "16. Average loss:0.9534940123558044, train_accuracy: 0.54,              val_accuracy: 0.55\n",
      "17. Average loss:0.9482358694076538, train_accuracy: 0.54,              val_accuracy: 0.54\n",
      "18. Average loss:0.9425623416900635, train_accuracy: 0.55,              val_accuracy: 0.54\n",
      "19. Average loss:0.937261700630188, train_accuracy: 0.55,              val_accuracy: 0.56\n",
      "20. Average loss:0.9317395091056824, train_accuracy: 0.55,              val_accuracy: 0.55\n",
      "21. Average loss:0.9259178638458252, train_accuracy: 0.56,              val_accuracy: 0.55\n",
      "22. Average loss:0.9199846386909485, train_accuracy: 0.56,              val_accuracy: 0.55\n",
      "23. Average loss:0.9144694805145264, train_accuracy: 0.57,              val_accuracy: 0.52\n",
      "24. Average loss:0.9083858132362366, train_accuracy: 0.57,              val_accuracy: 0.54\n",
      "25. Average loss:0.9030569195747375, train_accuracy: 0.57,              val_accuracy: 0.55\n",
      "26. Average loss:0.8972203135490417, train_accuracy: 0.58,              val_accuracy: 0.55\n",
      "27. Average loss:0.8918482065200806, train_accuracy: 0.58,              val_accuracy: 0.56\n",
      "28. Average loss:0.8867281079292297, train_accuracy: 0.58,              val_accuracy: 0.56\n",
      "29. Average loss:0.8809824585914612, train_accuracy: 0.59,              val_accuracy: 0.56\n",
      "30. Average loss:0.8753729462623596, train_accuracy: 0.59,              val_accuracy: 0.57\n",
      "31. Average loss:0.8700108528137207, train_accuracy: 0.59,              val_accuracy: 0.55\n",
      "32. Average loss:0.8644346594810486, train_accuracy: 0.6,              val_accuracy: 0.55\n",
      "33. Average loss:0.8591300249099731, train_accuracy: 0.6,              val_accuracy: 0.56\n",
      "34. Average loss:0.8534806966781616, train_accuracy: 0.6,              val_accuracy: 0.56\n",
      "35. Average loss:0.8479241728782654, train_accuracy: 0.61,              val_accuracy: 0.55\n",
      "36. Average loss:0.8425068855285645, train_accuracy: 0.61,              val_accuracy: 0.55\n",
      "37. Average loss:0.8366476893424988, train_accuracy: 0.61,              val_accuracy: 0.56\n",
      "38. Average loss:0.8313280344009399, train_accuracy: 0.62,              val_accuracy: 0.55\n",
      "39. Average loss:0.8255742788314819, train_accuracy: 0.62,              val_accuracy: 0.55\n",
      "40. Average loss:0.8196637630462646, train_accuracy: 0.62,              val_accuracy: 0.55\n",
      "41. Average loss:0.8148638606071472, train_accuracy: 0.63,              val_accuracy: 0.55\n",
      "42. Average loss:0.8091149926185608, train_accuracy: 0.63,              val_accuracy: 0.54\n",
      "43. Average loss:0.8031801581382751, train_accuracy: 0.63,              val_accuracy: 0.54\n",
      "44. Average loss:0.797886073589325, train_accuracy: 0.64,              val_accuracy: 0.56\n",
      "45. Average loss:0.7926973104476929, train_accuracy: 0.64,              val_accuracy: 0.55\n",
      "46. Average loss:0.7856636047363281, train_accuracy: 0.64,              val_accuracy: 0.55\n",
      "47. Average loss:0.7809388637542725, train_accuracy: 0.65,              val_accuracy: 0.55\n",
      "48. Average loss:0.7767103314399719, train_accuracy: 0.65,              val_accuracy: 0.55\n",
      "\u001b[32m[I 2023-02-15 00:54:29,306]\u001b[0m Trial 0 finished with value: 0.5498318221702252 and parameters: {'learning_rate': 1.5e-05, 'epochs': 49, 'LEN_STRI': 209, 'embed_dim': 138, 'hidden_dim': 230, 'n_layers': 1, 'dropout': 0.21036589764735192}. Best is trial 0 with value: 0.5498318221702252.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gleb/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3083092754306145 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Average loss:1.0039081573486328, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "1. Average loss:0.9939034581184387, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "2. Average loss:0.9903553128242493, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "3. Average loss:0.9819979667663574, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "4. Average loss:0.9672679901123047, train_accuracy: 0.54,              val_accuracy: 0.55\n",
      "5. Average loss:0.9547788500785828, train_accuracy: 0.54,              val_accuracy: 0.55\n",
      "6. Average loss:0.9427050352096558, train_accuracy: 0.55,              val_accuracy: 0.56\n",
      "7. Average loss:0.9321974515914917, train_accuracy: 0.56,              val_accuracy: 0.55\n",
      "8. Average loss:0.9221961498260498, train_accuracy: 0.57,              val_accuracy: 0.57\n",
      "9. Average loss:0.9122137427330017, train_accuracy: 0.57,              val_accuracy: 0.55\n",
      "10. Average loss:0.9022845029830933, train_accuracy: 0.58,              val_accuracy: 0.56\n",
      "11. Average loss:0.8923600912094116, train_accuracy: 0.59,              val_accuracy: 0.56\n",
      "12. Average loss:0.8824321031570435, train_accuracy: 0.59,              val_accuracy: 0.57\n",
      "13. Average loss:0.8722900152206421, train_accuracy: 0.6,              val_accuracy: 0.56\n",
      "14. Average loss:0.8622086048126221, train_accuracy: 0.6,              val_accuracy: 0.54\n",
      "15. Average loss:0.8521776795387268, train_accuracy: 0.61,              val_accuracy: 0.55\n",
      "16. Average loss:0.8419734239578247, train_accuracy: 0.62,              val_accuracy: 0.54\n",
      "17. Average loss:0.8314147591590881, train_accuracy: 0.62,              val_accuracy: 0.56\n",
      "18. Average loss:0.821346640586853, train_accuracy: 0.63,              val_accuracy: 0.55\n",
      "19. Average loss:0.8111905455589294, train_accuracy: 0.63,              val_accuracy: 0.54\n",
      "20. Average loss:0.8007532954216003, train_accuracy: 0.64,              val_accuracy: 0.55\n",
      "21. Average loss:0.790078341960907, train_accuracy: 0.65,              val_accuracy: 0.54\n",
      "22. Average loss:0.7791393995285034, train_accuracy: 0.65,              val_accuracy: 0.54\n",
      "23. Average loss:0.768790602684021, train_accuracy: 0.66,              val_accuracy: 0.54\n",
      "24. Average loss:0.7573147416114807, train_accuracy: 0.66,              val_accuracy: 0.54\n",
      "25. Average loss:0.7467389702796936, train_accuracy: 0.67,              val_accuracy: 0.54\n",
      "26. Average loss:0.7357202768325806, train_accuracy: 0.67,              val_accuracy: 0.53\n",
      "27. Average loss:0.7253533005714417, train_accuracy: 0.68,              val_accuracy: 0.53\n",
      "28. Average loss:0.7156150937080383, train_accuracy: 0.68,              val_accuracy: 0.52\n",
      "29. Average loss:0.7045015692710876, train_accuracy: 0.69,              val_accuracy: 0.52\n",
      "30. Average loss:0.6936986446380615, train_accuracy: 0.7,              val_accuracy: 0.51\n",
      "31. Average loss:0.6837431788444519, train_accuracy: 0.7,              val_accuracy: 0.52\n",
      "32. Average loss:0.6724001169204712, train_accuracy: 0.71,              val_accuracy: 0.51\n",
      "33. Average loss:0.6619411706924438, train_accuracy: 0.71,              val_accuracy: 0.51\n",
      "34. Average loss:0.6516859531402588, train_accuracy: 0.72,              val_accuracy: 0.51\n",
      "35. Average loss:0.6412062644958496, train_accuracy: 0.72,              val_accuracy: 0.51\n",
      "36. Average loss:0.6309719681739807, train_accuracy: 0.73,              val_accuracy: 0.5\n",
      "37. Average loss:0.6209387183189392, train_accuracy: 0.73,              val_accuracy: 0.51\n",
      "38. Average loss:0.6108715534210205, train_accuracy: 0.74,              val_accuracy: 0.51\n",
      "\u001b[32m[I 2023-02-15 01:48:15,183]\u001b[0m Trial 1 finished with value: 0.5118508974320558 and parameters: {'learning_rate': 1.5e-05, 'epochs': 39, 'LEN_STRI': 85, 'embed_dim': 233, 'hidden_dim': 244, 'n_layers': 1, 'dropout': 0.3083092754306145}. Best is trial 0 with value: 0.5498318221702252.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gleb/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.08135891277835482 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Average loss:1.007625699043274, train_accuracy: 0.52,              val_accuracy: 0.56\n",
      "1. Average loss:0.9956063628196716, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "2. Average loss:0.9942831993103027, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "3. Average loss:0.9926384687423706, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "4. Average loss:0.9877994656562805, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "5. Average loss:0.9775416254997253, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "6. Average loss:0.96943199634552, train_accuracy: 0.54,              val_accuracy: 0.56\n",
      "7. Average loss:0.9626584649085999, train_accuracy: 0.54,              val_accuracy: 0.55\n",
      "8. Average loss:0.9565050005912781, train_accuracy: 0.55,              val_accuracy: 0.56\n",
      "9. Average loss:0.9512262344360352, train_accuracy: 0.55,              val_accuracy: 0.55\n",
      "10. Average loss:0.9460016489028931, train_accuracy: 0.55,              val_accuracy: 0.54\n",
      "11. Average loss:0.9412303566932678, train_accuracy: 0.56,              val_accuracy: 0.54\n",
      "12. Average loss:0.936260998249054, train_accuracy: 0.56,              val_accuracy: 0.54\n",
      "13. Average loss:0.9312620759010315, train_accuracy: 0.56,              val_accuracy: 0.56\n",
      "14. Average loss:0.926715612411499, train_accuracy: 0.57,              val_accuracy: 0.56\n",
      "15. Average loss:0.9217944145202637, train_accuracy: 0.57,              val_accuracy: 0.56\n",
      "16. Average loss:0.9170131683349609, train_accuracy: 0.57,              val_accuracy: 0.55\n",
      "17. Average loss:0.9123224020004272, train_accuracy: 0.58,              val_accuracy: 0.53\n",
      "18. Average loss:0.907471239566803, train_accuracy: 0.58,              val_accuracy: 0.57\n",
      "19. Average loss:0.9031164050102234, train_accuracy: 0.58,              val_accuracy: 0.54\n",
      "20. Average loss:0.8984503149986267, train_accuracy: 0.59,              val_accuracy: 0.56\n",
      "21. Average loss:0.8937593698501587, train_accuracy: 0.59,              val_accuracy: 0.55\n",
      "22. Average loss:0.88877272605896, train_accuracy: 0.59,              val_accuracy: 0.55\n",
      "23. Average loss:0.8846802711486816, train_accuracy: 0.6,              val_accuracy: 0.55\n",
      "24. Average loss:0.8798151016235352, train_accuracy: 0.6,              val_accuracy: 0.55\n",
      "25. Average loss:0.8752440810203552, train_accuracy: 0.6,              val_accuracy: 0.56\n",
      "26. Average loss:0.870502233505249, train_accuracy: 0.6,              val_accuracy: 0.56\n",
      "27. Average loss:0.8658342361450195, train_accuracy: 0.61,              val_accuracy: 0.56\n",
      "28. Average loss:0.861549973487854, train_accuracy: 0.61,              val_accuracy: 0.55\n",
      "29. Average loss:0.856800377368927, train_accuracy: 0.61,              val_accuracy: 0.56\n",
      "30. Average loss:0.8523204326629639, train_accuracy: 0.61,              val_accuracy: 0.54\n",
      "31. Average loss:0.8474734425544739, train_accuracy: 0.62,              val_accuracy: 0.56\n",
      "32. Average loss:0.8429303765296936, train_accuracy: 0.62,              val_accuracy: 0.55\n",
      "33. Average loss:0.8385775089263916, train_accuracy: 0.62,              val_accuracy: 0.55\n",
      "34. Average loss:0.8337982892990112, train_accuracy: 0.63,              val_accuracy: 0.55\n",
      "35. Average loss:0.8292762041091919, train_accuracy: 0.63,              val_accuracy: 0.55\n",
      "36. Average loss:0.825168788433075, train_accuracy: 0.63,              val_accuracy: 0.55\n",
      "37. Average loss:0.8204420208930969, train_accuracy: 0.63,              val_accuracy: 0.54\n",
      "38. Average loss:0.81607985496521, train_accuracy: 0.64,              val_accuracy: 0.54\n",
      "39. Average loss:0.8118669390678406, train_accuracy: 0.64,              val_accuracy: 0.54\n",
      "\u001b[32m[I 2023-02-15 02:23:22,486]\u001b[0m Trial 2 finished with value: 0.5397289514936574 and parameters: {'learning_rate': 1.5e-05, 'epochs': 40, 'LEN_STRI': 63, 'embed_dim': 119, 'hidden_dim': 118, 'n_layers': 1, 'dropout': 0.08135891277835482}. Best is trial 0 with value: 0.5498318221702252.\u001b[0m\n",
      "0. Average loss:0.9995608925819397, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "1. Average loss:0.9945290088653564, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "2. Average loss:0.9919300675392151, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "3. Average loss:0.9849644899368286, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "4. Average loss:0.9736851453781128, train_accuracy: 0.53,              val_accuracy: 0.55\n",
      "5. Average loss:0.9631549715995789, train_accuracy: 0.53,              val_accuracy: 0.54\n",
      "6. Average loss:0.953558087348938, train_accuracy: 0.54,              val_accuracy: 0.55\n",
      "7. Average loss:0.9452561736106873, train_accuracy: 0.55,              val_accuracy: 0.55\n",
      "8. Average loss:0.9367944002151489, train_accuracy: 0.55,              val_accuracy: 0.56\n",
      "9. Average loss:0.929410457611084, train_accuracy: 0.56,              val_accuracy: 0.56\n",
      "10. Average loss:0.922943651676178, train_accuracy: 0.57,              val_accuracy: 0.56\n",
      "11. Average loss:0.9164053797721863, train_accuracy: 0.57,              val_accuracy: 0.56\n",
      "12. Average loss:0.9101715087890625, train_accuracy: 0.57,              val_accuracy: 0.57\n",
      "13. Average loss:0.9038323760032654, train_accuracy: 0.58,              val_accuracy: 0.55\n",
      "14. Average loss:0.8975042700767517, train_accuracy: 0.58,              val_accuracy: 0.56\n",
      "15. Average loss:0.8906816840171814, train_accuracy: 0.59,              val_accuracy: 0.56\n",
      "16. Average loss:0.8850821852684021, train_accuracy: 0.59,              val_accuracy: 0.57\n",
      "17. Average loss:0.879043459892273, train_accuracy: 0.6,              val_accuracy: 0.56\n",
      "18. Average loss:0.8730012774467468, train_accuracy: 0.6,              val_accuracy: 0.55\n",
      "19. Average loss:0.8668526411056519, train_accuracy: 0.6,              val_accuracy: 0.57\n",
      "20. Average loss:0.8610436916351318, train_accuracy: 0.61,              val_accuracy: 0.56\n",
      "21. Average loss:0.8545174598693848, train_accuracy: 0.61,              val_accuracy: 0.56\n",
      "22. Average loss:0.8483197093009949, train_accuracy: 0.62,              val_accuracy: 0.56\n",
      "23. Average loss:0.8428571224212646, train_accuracy: 0.62,              val_accuracy: 0.56\n",
      "24. Average loss:0.8362461924552917, train_accuracy: 0.62,              val_accuracy: 0.56\n",
      "25. Average loss:0.8297503590583801, train_accuracy: 0.63,              val_accuracy: 0.54\n",
      "26. Average loss:0.8241894841194153, train_accuracy: 0.63,              val_accuracy: 0.55\n",
      "\u001b[32m[I 2023-02-15 03:41:18,923]\u001b[0m Trial 3 finished with value: 0.5491866299773389 and parameters: {'learning_rate': 1.5e-05, 'epochs': 27, 'LEN_STRI': 115, 'embed_dim': 135, 'hidden_dim': 95, 'n_layers': 3, 'dropout': 0.18862280621075175}. Best is trial 0 with value: 0.5498318221702252.\u001b[0m\n",
      "0. Average loss:1.0010161399841309, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "1. Average loss:0.9940489530563354, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "2. Average loss:0.9910669326782227, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "3. Average loss:0.980848491191864, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "4. Average loss:0.9651157259941101, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "5. Average loss:0.9532409906387329, train_accuracy: 0.54,              val_accuracy: 0.55\n",
      "6. Average loss:0.9424929022789001, train_accuracy: 0.55,              val_accuracy: 0.56\n",
      "7. Average loss:0.9328083395957947, train_accuracy: 0.56,              val_accuracy: 0.56\n",
      "8. Average loss:0.9237372875213623, train_accuracy: 0.56,              val_accuracy: 0.56\n",
      "9. Average loss:0.9157910346984863, train_accuracy: 0.57,              val_accuracy: 0.54\n",
      "10. Average loss:0.9064882397651672, train_accuracy: 0.58,              val_accuracy: 0.55\n",
      "11. Average loss:0.8993949890136719, train_accuracy: 0.58,              val_accuracy: 0.56\n",
      "12. Average loss:0.8907597661018372, train_accuracy: 0.59,              val_accuracy: 0.56\n",
      "13. Average loss:0.8824600577354431, train_accuracy: 0.59,              val_accuracy: 0.57\n",
      "14. Average loss:0.8744844794273376, train_accuracy: 0.6,              val_accuracy: 0.56\n",
      "15. Average loss:0.8672211170196533, train_accuracy: 0.6,              val_accuracy: 0.56\n",
      "16. Average loss:0.8589652180671692, train_accuracy: 0.61,              val_accuracy: 0.57\n",
      "17. Average loss:0.8518744111061096, train_accuracy: 0.61,              val_accuracy: 0.57\n",
      "18. Average loss:0.8427644968032837, train_accuracy: 0.62,              val_accuracy: 0.57\n",
      "19. Average loss:0.8348784446716309, train_accuracy: 0.62,              val_accuracy: 0.55\n",
      "20. Average loss:0.8262049555778503, train_accuracy: 0.63,              val_accuracy: 0.56\n",
      "21. Average loss:0.8186410069465637, train_accuracy: 0.63,              val_accuracy: 0.56\n",
      "22. Average loss:0.810025691986084, train_accuracy: 0.64,              val_accuracy: 0.55\n",
      "23. Average loss:0.8017140626907349, train_accuracy: 0.64,              val_accuracy: 0.56\n",
      "24. Average loss:0.7930006980895996, train_accuracy: 0.65,              val_accuracy: 0.56\n",
      "25. Average loss:0.7855591773986816, train_accuracy: 0.65,              val_accuracy: 0.56\n",
      "\u001b[32m[I 2023-02-15 04:54:21,624]\u001b[0m Trial 4 finished with value: 0.5594506213211249 and parameters: {'learning_rate': 1.5e-05, 'epochs': 26, 'LEN_STRI': 124, 'embed_dim': 181, 'hidden_dim': 106, 'n_layers': 2, 'dropout': 0.17038101483119195}. Best is trial 4 with value: 0.5594506213211249.\u001b[0m\n",
      "0. Average loss:1.0076481103897095, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "1. Average loss:0.9955708384513855, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "2. Average loss:0.9940184354782104, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "3. Average loss:0.9922255277633667, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "4. Average loss:0.9892556071281433, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "5. Average loss:0.9795497059822083, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "6. Average loss:0.9692373275756836, train_accuracy: 0.53,              val_accuracy: 0.54\n",
      "7. Average loss:0.960686981678009, train_accuracy: 0.54,              val_accuracy: 0.55\n",
      "8. Average loss:0.9526967406272888, train_accuracy: 0.55,              val_accuracy: 0.56\n",
      "9. Average loss:0.9463294148445129, train_accuracy: 0.55,              val_accuracy: 0.55\n",
      "10. Average loss:0.9396984577178955, train_accuracy: 0.55,              val_accuracy: 0.56\n",
      "11. Average loss:0.93354731798172, train_accuracy: 0.56,              val_accuracy: 0.56\n",
      "12. Average loss:0.9268285632133484, train_accuracy: 0.56,              val_accuracy: 0.56\n",
      "13. Average loss:0.9201173186302185, train_accuracy: 0.57,              val_accuracy: 0.56\n",
      "14. Average loss:0.9140385389328003, train_accuracy: 0.57,              val_accuracy: 0.56\n",
      "15. Average loss:0.9077626466751099, train_accuracy: 0.57,              val_accuracy: 0.57\n",
      "16. Average loss:0.9017870426177979, train_accuracy: 0.58,              val_accuracy: 0.57\n",
      "17. Average loss:0.8962335586547852, train_accuracy: 0.58,              val_accuracy: 0.56\n",
      "18. Average loss:0.8904589414596558, train_accuracy: 0.59,              val_accuracy: 0.56\n",
      "19. Average loss:0.8853707909584045, train_accuracy: 0.59,              val_accuracy: 0.57\n",
      "20. Average loss:0.8789915442466736, train_accuracy: 0.59,              val_accuracy: 0.55\n",
      "21. Average loss:0.8737304210662842, train_accuracy: 0.6,              val_accuracy: 0.57\n",
      "22. Average loss:0.8673441410064697, train_accuracy: 0.6,              val_accuracy: 0.55\n",
      "23. Average loss:0.8616979718208313, train_accuracy: 0.6,              val_accuracy: 0.56\n",
      "24. Average loss:0.8552289009094238, train_accuracy: 0.61,              val_accuracy: 0.56\n",
      "25. Average loss:0.8511714339256287, train_accuracy: 0.61,              val_accuracy: 0.55\n",
      "26. Average loss:0.8462658524513245, train_accuracy: 0.61,              val_accuracy: 0.57\n",
      "27. Average loss:0.8393364548683167, train_accuracy: 0.62,              val_accuracy: 0.57\n",
      "28. Average loss:0.8336196541786194, train_accuracy: 0.62,              val_accuracy: 0.56\n",
      "29. Average loss:0.8280010223388672, train_accuracy: 0.62,              val_accuracy: 0.56\n",
      "30. Average loss:0.8228960037231445, train_accuracy: 0.63,              val_accuracy: 0.54\n",
      "\u001b[32m[I 2023-02-15 05:52:25,348]\u001b[0m Trial 5 finished with value: 0.5408669564214008 and parameters: {'learning_rate': 1.5e-05, 'epochs': 31, 'LEN_STRI': 220, 'embed_dim': 143, 'hidden_dim': 240, 'n_layers': 2, 'dropout': 0.24885057811978842}. Best is trial 4 with value: 0.5594506213211249.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gleb/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.054790579723988445 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Average loss:1.0114755630493164, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "1. Average loss:0.9959766864776611, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "2. Average loss:0.9939756989479065, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "3. Average loss:0.9920318722724915, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "4. Average loss:0.9897377490997314, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "5. Average loss:0.9868214726448059, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "6. Average loss:0.982572615146637, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "7. Average loss:0.9726567268371582, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "8. Average loss:0.9603467583656311, train_accuracy: 0.54,              val_accuracy: 0.55\n",
      "9. Average loss:0.950771689414978, train_accuracy: 0.54,              val_accuracy: 0.55\n",
      "10. Average loss:0.941545844078064, train_accuracy: 0.55,              val_accuracy: 0.55\n",
      "11. Average loss:0.933742344379425, train_accuracy: 0.55,              val_accuracy: 0.56\n",
      "12. Average loss:0.9257057905197144, train_accuracy: 0.56,              val_accuracy: 0.56\n",
      "13. Average loss:0.9185293316841125, train_accuracy: 0.56,              val_accuracy: 0.55\n",
      "14. Average loss:0.9112141132354736, train_accuracy: 0.57,              val_accuracy: 0.56\n",
      "15. Average loss:0.9036476612091064, train_accuracy: 0.57,              val_accuracy: 0.55\n",
      "16. Average loss:0.8960328102111816, train_accuracy: 0.58,              val_accuracy: 0.55\n",
      "17. Average loss:0.8887559175491333, train_accuracy: 0.58,              val_accuracy: 0.55\n",
      "18. Average loss:0.8817059993743896, train_accuracy: 0.59,              val_accuracy: 0.55\n",
      "19. Average loss:0.8743900656700134, train_accuracy: 0.59,              val_accuracy: 0.55\n",
      "20. Average loss:0.8677911758422852, train_accuracy: 0.59,              val_accuracy: 0.52\n",
      "21. Average loss:0.8600018620491028, train_accuracy: 0.6,              val_accuracy: 0.54\n",
      "22. Average loss:0.8528299331665039, train_accuracy: 0.6,              val_accuracy: 0.54\n",
      "23. Average loss:0.8455126285552979, train_accuracy: 0.61,              val_accuracy: 0.55\n",
      "24. Average loss:0.8377792239189148, train_accuracy: 0.61,              val_accuracy: 0.53\n",
      "25. Average loss:0.8309056162834167, train_accuracy: 0.62,              val_accuracy: 0.52\n",
      "26. Average loss:0.8249914646148682, train_accuracy: 0.62,              val_accuracy: 0.55\n",
      "27. Average loss:0.8155344724655151, train_accuracy: 0.62,              val_accuracy: 0.53\n",
      "28. Average loss:0.8086851239204407, train_accuracy: 0.63,              val_accuracy: 0.54\n",
      "29. Average loss:0.8014032244682312, train_accuracy: 0.63,              val_accuracy: 0.55\n",
      "30. Average loss:0.7940834164619446, train_accuracy: 0.64,              val_accuracy: 0.53\n",
      "31. Average loss:0.7855708003044128, train_accuracy: 0.64,              val_accuracy: 0.55\n",
      "32. Average loss:0.7789140343666077, train_accuracy: 0.65,              val_accuracy: 0.54\n",
      "33. Average loss:0.7767499685287476, train_accuracy: 0.65,              val_accuracy: 0.54\n",
      "34. Average loss:0.761500895023346, train_accuracy: 0.66,              val_accuracy: 0.53\n",
      "35. Average loss:0.755767285823822, train_accuracy: 0.66,              val_accuracy: 0.55\n",
      "36. Average loss:0.7476799488067627, train_accuracy: 0.66,              val_accuracy: 0.53\n",
      "37. Average loss:0.7406127452850342, train_accuracy: 0.67,              val_accuracy: 0.53\n",
      "38. Average loss:0.7318955063819885, train_accuracy: 0.67,              val_accuracy: 0.54\n",
      "39. Average loss:0.7234567999839783, train_accuracy: 0.68,              val_accuracy: 0.51\n",
      "40. Average loss:0.7167377471923828, train_accuracy: 0.68,              val_accuracy: 0.53\n",
      "41. Average loss:0.7064484357833862, train_accuracy: 0.69,              val_accuracy: 0.52\n",
      "42. Average loss:0.6999161243438721, train_accuracy: 0.69,              val_accuracy: 0.51\n",
      "43. Average loss:0.6921582818031311, train_accuracy: 0.69,              val_accuracy: 0.53\n",
      "44. Average loss:0.6822578310966492, train_accuracy: 0.7,              val_accuracy: 0.52\n",
      "45. Average loss:0.677017867565155, train_accuracy: 0.7,              val_accuracy: 0.52\n",
      "46. Average loss:0.6669321060180664, train_accuracy: 0.71,              val_accuracy: 0.52\n",
      "47. Average loss:0.6591352224349976, train_accuracy: 0.71,              val_accuracy: 0.51\n",
      "\u001b[32m[I 2023-02-15 07:04:32,004]\u001b[0m Trial 6 finished with value: 0.5083675484642171 and parameters: {'learning_rate': 1.5e-05, 'epochs': 48, 'LEN_STRI': 148, 'embed_dim': 191, 'hidden_dim': 92, 'n_layers': 1, 'dropout': 0.054790579723988445}. Best is trial 4 with value: 0.5594506213211249.\u001b[0m\n",
      "0. Average loss:1.0006706714630127, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "1. Average loss:0.9937894344329834, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "2. Average loss:0.9897719621658325, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "3. Average loss:0.9816277027130127, train_accuracy: 0.53,              val_accuracy: 0.55\n",
      "4. Average loss:0.9641736149787903, train_accuracy: 0.54,              val_accuracy: 0.55\n",
      "5. Average loss:0.9521710872650146, train_accuracy: 0.55,              val_accuracy: 0.56\n",
      "6. Average loss:0.9477804899215698, train_accuracy: 0.55,              val_accuracy: 0.56\n",
      "7. Average loss:0.9469692707061768, train_accuracy: 0.55,              val_accuracy: 0.56\n",
      "8. Average loss:0.9358072280883789, train_accuracy: 0.56,              val_accuracy: 0.53\n",
      "9. Average loss:0.9347400069236755, train_accuracy: 0.56,              val_accuracy: 0.56\n",
      "10. Average loss:0.9297606945037842, train_accuracy: 0.56,              val_accuracy: 0.56\n",
      "11. Average loss:0.9153891801834106, train_accuracy: 0.57,              val_accuracy: 0.55\n",
      "12. Average loss:0.9103394746780396, train_accuracy: 0.58,              val_accuracy: 0.57\n",
      "13. Average loss:0.9007954001426697, train_accuracy: 0.58,              val_accuracy: 0.55\n",
      "14. Average loss:0.8966864943504333, train_accuracy: 0.59,              val_accuracy: 0.57\n",
      "15. Average loss:0.8921319842338562, train_accuracy: 0.59,              val_accuracy: 0.56\n",
      "16. Average loss:0.8815646171569824, train_accuracy: 0.59,              val_accuracy: 0.57\n",
      "17. Average loss:0.8739813566207886, train_accuracy: 0.6,              val_accuracy: 0.57\n",
      "18. Average loss:0.8635839223861694, train_accuracy: 0.61,              val_accuracy: 0.57\n",
      "19. Average loss:0.854354202747345, train_accuracy: 0.61,              val_accuracy: 0.55\n",
      "20. Average loss:0.8431630730628967, train_accuracy: 0.62,              val_accuracy: 0.57\n",
      "21. Average loss:0.8340874314308167, train_accuracy: 0.62,              val_accuracy: 0.55\n",
      "22. Average loss:0.8215787410736084, train_accuracy: 0.63,              val_accuracy: 0.55\n",
      "23. Average loss:0.809549868106842, train_accuracy: 0.64,              val_accuracy: 0.56\n",
      "24. Average loss:0.7976401448249817, train_accuracy: 0.64,              val_accuracy: 0.57\n",
      "\u001b[32m[I 2023-02-15 08:09:21,718]\u001b[0m Trial 7 finished with value: 0.5672567328838736 and parameters: {'learning_rate': 1.5e-05, 'epochs': 25, 'LEN_STRI': 206, 'embed_dim': 245, 'hidden_dim': 37, 'n_layers': 3, 'dropout': 0.3926691382178267}. Best is trial 7 with value: 0.5672567328838736.\u001b[0m\n",
      "0. Average loss:1.0079437494277954, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "1. Average loss:0.995835542678833, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "2. Average loss:0.9945622086524963, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "3. Average loss:0.9929498434066772, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "4. Average loss:0.9904985427856445, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "5. Average loss:0.9841457009315491, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "6. Average loss:0.9736235737800598, train_accuracy: 0.53,              val_accuracy: 0.55\n",
      "7. Average loss:0.9666780233383179, train_accuracy: 0.53,              val_accuracy: 0.55\n",
      "8. Average loss:0.9594521522521973, train_accuracy: 0.54,              val_accuracy: 0.53\n",
      "9. Average loss:0.9518511295318604, train_accuracy: 0.54,              val_accuracy: 0.56\n",
      "10. Average loss:0.943092942237854, train_accuracy: 0.55,              val_accuracy: 0.55\n",
      "11. Average loss:0.9346946477890015, train_accuracy: 0.55,              val_accuracy: 0.55\n",
      "12. Average loss:0.9258776307106018, train_accuracy: 0.56,              val_accuracy: 0.54\n",
      "13. Average loss:0.9184093475341797, train_accuracy: 0.56,              val_accuracy: 0.49\n",
      "14. Average loss:0.9116023182868958, train_accuracy: 0.57,              val_accuracy: 0.57\n",
      "15. Average loss:0.9050001502037048, train_accuracy: 0.57,              val_accuracy: 0.57\n",
      "16. Average loss:0.8975130319595337, train_accuracy: 0.58,              val_accuracy: 0.56\n",
      "17. Average loss:0.89170241355896, train_accuracy: 0.58,              val_accuracy: 0.56\n",
      "18. Average loss:0.8856390118598938, train_accuracy: 0.59,              val_accuracy: 0.52\n",
      "19. Average loss:0.8784134984016418, train_accuracy: 0.59,              val_accuracy: 0.55\n",
      "20. Average loss:0.8733340501785278, train_accuracy: 0.59,              val_accuracy: 0.54\n",
      "21. Average loss:0.8673511147499084, train_accuracy: 0.6,              val_accuracy: 0.52\n",
      "22. Average loss:0.8606550693511963, train_accuracy: 0.6,              val_accuracy: 0.52\n",
      "23. Average loss:0.8539307117462158, train_accuracy: 0.61,              val_accuracy: 0.54\n",
      "24. Average loss:0.8494477272033691, train_accuracy: 0.61,              val_accuracy: 0.53\n",
      "25. Average loss:0.843163251876831, train_accuracy: 0.61,              val_accuracy: 0.55\n",
      "26. Average loss:0.8377073407173157, train_accuracy: 0.62,              val_accuracy: 0.56\n",
      "27. Average loss:0.831824779510498, train_accuracy: 0.62,              val_accuracy: 0.55\n",
      "28. Average loss:0.8239572644233704, train_accuracy: 0.63,              val_accuracy: 0.55\n",
      "29. Average loss:0.8187336325645447, train_accuracy: 0.63,              val_accuracy: 0.55\n",
      "30. Average loss:0.8132222294807434, train_accuracy: 0.63,              val_accuracy: 0.56\n",
      "31. Average loss:0.8068687319755554, train_accuracy: 0.64,              val_accuracy: 0.57\n",
      "\u001b[32m[I 2023-02-15 09:12:32,740]\u001b[0m Trial 8 finished with value: 0.5667699572082042 and parameters: {'learning_rate': 1.5e-05, 'epochs': 32, 'LEN_STRI': 211, 'embed_dim': 151, 'hidden_dim': 17, 'n_layers': 2, 'dropout': 0.2512337086827091}. Best is trial 7 with value: 0.5672567328838736.\u001b[0m\n",
      "0. Average loss:1.0241681337356567, train_accuracy: 0.51,              val_accuracy: 0.56\n",
      "1. Average loss:0.997760534286499, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "2. Average loss:0.9972254633903503, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "3. Average loss:0.9968248009681702, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "4. Average loss:0.9965379238128662, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "5. Average loss:0.9962788224220276, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "6. Average loss:0.995954155921936, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "7. Average loss:0.9956411719322205, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "8. Average loss:0.9954150915145874, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "9. Average loss:0.9951850771903992, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "10. Average loss:0.9948501586914062, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "11. Average loss:0.9944913983345032, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "12. Average loss:0.9942091107368469, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "13. Average loss:0.9939184188842773, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "14. Average loss:0.9935780167579651, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "15. Average loss:0.9932014346122742, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "16. Average loss:0.9927689433097839, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "17. Average loss:0.9923136234283447, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "18. Average loss:0.9914475083351135, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "19. Average loss:0.9904837012290955, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "20. Average loss:0.988194465637207, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "21. Average loss:0.9865090250968933, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "22. Average loss:0.9841539859771729, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "23. Average loss:0.9837661385536194, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "24. Average loss:0.9833091497421265, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "25. Average loss:0.9836178421974182, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "26. Average loss:0.9834954142570496, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "27. Average loss:0.9820035696029663, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "28. Average loss:0.9808863401412964, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "\u001b[32m[I 2023-02-15 09:23:32,052]\u001b[0m Trial 9 finished with value: 0.5575299509528021 and parameters: {'learning_rate': 1.5e-05, 'epochs': 29, 'LEN_STRI': 230, 'embed_dim': 44, 'hidden_dim': 58, 'n_layers': 2, 'dropout': 0.3387510162766405}. Best is trial 7 with value: 0.5672567328838736.\u001b[0m\n",
      "0. Average loss:1.0042167901992798, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "1. Average loss:0.9963306188583374, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "2. Average loss:0.9958879351615906, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "3. Average loss:0.9954724907875061, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "4. Average loss:0.9950024485588074, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "5. Average loss:0.9944182634353638, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "6. Average loss:0.9938603639602661, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "7. Average loss:0.9934065341949463, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "8. Average loss:0.9926953315734863, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "9. Average loss:0.9920094609260559, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "10. Average loss:0.991057276725769, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "11. Average loss:0.9900189638137817, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "12. Average loss:0.9886236190795898, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "13. Average loss:0.9870588779449463, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "14. Average loss:0.983866274356842, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "15. Average loss:0.9784422516822815, train_accuracy: 0.53,              val_accuracy: 0.55\n",
      "16. Average loss:0.973150908946991, train_accuracy: 0.53,              val_accuracy: 0.55\n",
      "17. Average loss:0.9693572521209717, train_accuracy: 0.53,              val_accuracy: 0.55\n",
      "18. Average loss:0.9652878642082214, train_accuracy: 0.54,              val_accuracy: 0.55\n",
      "19. Average loss:0.9622780084609985, train_accuracy: 0.54,              val_accuracy: 0.55\n",
      "20. Average loss:0.9584590792655945, train_accuracy: 0.54,              val_accuracy: 0.55\n",
      "21. Average loss:0.9545708298683167, train_accuracy: 0.54,              val_accuracy: 0.55\n",
      "22. Average loss:0.950584888458252, train_accuracy: 0.55,              val_accuracy: 0.53\n",
      "23. Average loss:0.9473146796226501, train_accuracy: 0.55,              val_accuracy: 0.54\n",
      "24. Average loss:0.9449319839477539, train_accuracy: 0.55,              val_accuracy: 0.53\n",
      "25. Average loss:0.9406986236572266, train_accuracy: 0.56,              val_accuracy: 0.53\n",
      "26. Average loss:0.9384831190109253, train_accuracy: 0.56,              val_accuracy: 0.53\n",
      "27. Average loss:0.9345454573631287, train_accuracy: 0.56,              val_accuracy: 0.54\n",
      "28. Average loss:0.9327537417411804, train_accuracy: 0.56,              val_accuracy: 0.48\n",
      "29. Average loss:0.9282515048980713, train_accuracy: 0.56,              val_accuracy: 0.56\n",
      "30. Average loss:0.9252293109893799, train_accuracy: 0.56,              val_accuracy: 0.51\n",
      "31. Average loss:0.9239800572395325, train_accuracy: 0.57,              val_accuracy: 0.54\n",
      "32. Average loss:0.9213474988937378, train_accuracy: 0.57,              val_accuracy: 0.54\n",
      "33. Average loss:0.9168168902397156, train_accuracy: 0.57,              val_accuracy: 0.55\n",
      "\u001b[32m[I 2023-02-15 09:44:42,507]\u001b[0m Trial 10 finished with value: 0.5524855138761817 and parameters: {'learning_rate': 1.5e-05, 'epochs': 34, 'LEN_STRI': 174, 'embed_dim': 67, 'hidden_dim': 180, 'n_layers': 3, 'dropout': 0.3907330161564974}. Best is trial 7 with value: 0.5672567328838736.\u001b[0m\n",
      "0. Average loss:1.0004099607467651, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "1. Average loss:0.9940642714500427, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "2. Average loss:0.9903859496116638, train_accuracy: 0.53,              val_accuracy: 0.56\n",
      "3. Average loss:0.9796887040138245, train_accuracy: 0.53,              val_accuracy: 0.55\n",
      "4. Average loss:0.9598013758659363, train_accuracy: 0.54,              val_accuracy: 0.54\n",
      "5. Average loss:0.9467885494232178, train_accuracy: 0.55,              val_accuracy: 0.54\n",
      "6. Average loss:0.9331375360488892, train_accuracy: 0.56,              val_accuracy: 0.54\n",
      "7. Average loss:0.9212685823440552, train_accuracy: 0.56,              val_accuracy: 0.54\n",
      "8. Average loss:0.9133907556533813, train_accuracy: 0.57,              val_accuracy: 0.57\n",
      "9. Average loss:0.9068959951400757, train_accuracy: 0.58,              val_accuracy: 0.54\n",
      "10. Average loss:0.9073842167854309, train_accuracy: 0.58,              val_accuracy: 0.54\n",
      "11. Average loss:0.8937894105911255, train_accuracy: 0.59,              val_accuracy: 0.57\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=10000, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a86a36-5212-4507-bc9a-6860a490b79a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
